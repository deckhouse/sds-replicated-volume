- name: kubernetes.pv.settings_check
  rules:
    - alert: ReplicatedPVWithIncorrectSettings
      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_linstor_settings_mismatch="true", label_storage_deckhouse_io_linstor_settings_mismatch_ignore!="true"}) > 0
      for: 5m
      labels:
        severity_level: "4"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: Replicated PVs has incorrect settings
        description: |
          There are persistent volumes in the cluster that were created before migration to ReplicatedStorageClass.
          You can recreate it, or add the label storage.deckhouse.io/linstor-settings-mismatch-ignore!=true to ignore it for the PV.
          Please note that in the future, when transitioning from LINSTOR to a new controller, the settings for all such PVs will be automatically modified to match the current StorageClass settings.
          
          You can view all of such PV with command
          `kubectl get pv -l storage.deckhouse.io/linstor-settings-mismatch=true,storage.deckhouse.io/linstor-settings-mismatch-ignore!=true`
          
          Also, you can add label for all incorrect PVs
          `kubectl label pv -l storage.deckhouse.io/linstor-settings-mismatch=true storage.deckhouse.io/linstor-settings-mismatch-ignore=true`
    - alert: ReplicatedPVWithIncorrectQuorumMinimumRedundancy
      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_unable_to_set_quorum_minimum_redundancy="true"}) > 0
      for: 5m
      labels:
        severity_level: "3"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: Replicated PVs has incorrect quorum-minimum-redundancy setting
        description: |
          Persistent volumes in the cluster has incorrect quorum-minimum-redundancy setting.
          
          Please, contact tech support for assistance.
#    - alert: ReplicatedPVIncorrectReplicasCountFatalS3
#      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="fatal"}) > 0
#      for: 15m
#      labels:
#        severity_level: "3"
#        tier: cluster
#      annotations:
#        plk_markup_format: "markdown"
#        plk_protocol_version: "1"
#        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        summary: Replicated PVs has not enough replicas
#        description: |
#          Persistent volumes in the cluster has less then 2 replicas (set of UpToDate resources)
##          
##          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
##          And view all Resource States with `linstor r l`
#    - alert: ReplicatedPVIncorrectReplicasCountErrorS3
#      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="error", label_storage_deckhouse_io_pv_not_enough_replicas="fatal"}) > 0
#      for: 30m
#      labels:
#        severity_level: "3"
#        tier: cluster
#      annotations:
#        plk_markup_format: "markdown"
#        plk_protocol_version: "1"
#        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        summary: Replicated PVs has not enough replicas
#        description: |
#          Persistent volumes in the cluster has not enough replicas for quorum for 30min (set of UpToDate resources)
##          
##          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
##          And view all Resource States with `linstor r l`
#    - alert: ReplicatedPVIncorrectReplicasCountWarningS3
#      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="warning", label_storage_deckhouse_io_pv_not_enough_replicas="error", label_storage_deckhouse_io_pv_not_enough_replicas="fatal"}) > 0
#      for: 24h
#      labels:
#        severity_level: "3"
#        tier: cluster
#      annotations:
#        plk_markup_format: "markdown"
#        plk_protocol_version: "1"
#        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        summary: Replicated PVs has not enough replicas
#        description: |
#          Persistent volumes in the cluster has not enough replicas for long time (set of UpToDate resources less than minimal count)
##          
##          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
##          And view all Resource States with `linstor r l`
#    - alert: ReplicatedPVIncorrectReplicasCountErrorS4
#      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="error", label_storage_deckhouse_io_pv_not_enough_replicas="fatal"}) > 0
#      for: 15m
#      labels:
#        severity_level: "4"
#        tier: cluster
#      annotations:
#        plk_markup_format: "markdown"
#        plk_protocol_version: "1"
#        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        summary: Replicated PVs has not enough replicas
#        description: |
#          Persistent volumes in the cluster has not enough replicas for quorum for 15min (set of UpToDate resources)
##          
##          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
##          And view all Resource States with `linstor r l`
#    - alert: ReplicatedPVIncorrectReplicasCountWarningS4
#      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="warning", label_storage_deckhouse_io_pv_not_enough_replicas="error", label_storage_deckhouse_io_pv_not_enough_replicas="fatal"}) > 0
#      for: 30m
#      labels:
#        severity_level: "4"
#        tier: cluster
#      annotations:
#        plk_markup_format: "markdown"
#        plk_protocol_version: "1"
#        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
#        summary: Replicated PVs has not enough replicas
#        description: |
#          Persistent volumes in the cluster has not enough replicas for 30min (set of UpToDate resources less than minimal count)
##          
##          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
##          And view all Resource States with `linstor r l`
    - alert: ReplicatedPVIncorrectReplicasCountWarningS5
      expr: count(kube_persistentvolume_labels{label_storage_deckhouse_io_pv_not_enough_replicas="warning|error|fatal"}) > 0
      for: 5m
      labels:
        severity_level: "5"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_drbd_device_health: "ReplicatedPVSettingsCheck,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: Replicated PVs has not enough replicas
        description: |
          Persistent volumes in the cluster has not enough replicas (set of UpToDate resources less than minimal count)
#          
#          You can get minimal limit for StorageClass with command `kubectl get sc -o yaml | grep -E "(\sname|placementCount)"`
#          And view all Resource States with `linstor r l`
